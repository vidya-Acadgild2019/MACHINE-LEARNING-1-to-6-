{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Problem Statement: Machine Learning 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. What are the three stages to build the hypotheses or model in machine learning?\n",
    " \n",
    "a)Model building-It involves identifying the input paramters, type of model, etc.\n",
    "b)Model testing-It involves running the model so see the results and compare the output values with actual values\n",
    "c)Applying the model - It involves using the model for new dataset to predict the values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What is the standard approach to supervised learning?\n",
    "\n",
    "The standard approach to supervised learning is to split the set of example into the training set and the test. In supervised learning, a model is created by using labeled training data that consists of input data and an expected output. \n",
    "The expected output is compared with actual output and adjustments are done in the model based on that.\n",
    "When trained, you can apply this model to test set to verify the output from the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What is Training set and Test set?\n",
    "\n",
    "In various areas of information science like machine learning, a set of data is used to discover the potentially predictive relationship known as ‘Training Set’. Training set is an examples given to the learner, while Test set is used to test the accuracy of the hypotheses generated by the learner, and it is the set of example held back from the learner. Training set are distinct from Test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What is the general principle of an ensemble method and what is bagging and boosting in ensemble method?\n",
    "\n",
    "The general principle of an ensemble method is to combine the predictions of several models built with a given learning algorithm in order to improve robustness over a single model.  Ensemble methods are meta-algorithms that combine several machine learning techniques into one predictive model in order to decrease variance (bagging), bias (boosting), or improve predictions (stacking).\n",
    "\n",
    "Bagging:\n",
    "Bagging is a method in ensemble for improving unstable estimation or classification schemes. Bagging stands for bootstrap aggregation. In this method, random samples of the training data set (sub sets of training data set) are created.\n",
    "Then, a classifier is built for each sample. Finally, results of these multiple classifiers are combined using average or majority voting. Bagging helps to reduce the variance error.\n",
    " \n",
    "\n",
    "Boosting:\n",
    "While boosting method are used sequentially to reduce the bias of the combined model.  Boosting employes logic in which subsequent predictors learn from the mistakes of the previous predictors. Therefore, observation have unequal probability of appearing in subsequent models and one with highest error appear most.Boosting and Bagging both can reduce errors by reducing the variance term.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. How can you avoid overfitting?\n",
    "\n",
    "By using a lot of data overfitting can be avoided, overfitting happens relatively as you have a small dataset, and you try to learn from it. But if you have a small database and you are forced to come with a model based on that. In such situation, you can use a technique known as cross validation. In this method the dataset splits into two section, testing and training datasets, the testing dataset will only test the model while, in training dataset, the datapoints will come up with the model.\n",
    "In this technique, a model is usually given a dataset of a known data on which training (training data set) is run and a dataset of unknown data against which the model is tested. The idea of cross validation is to define a dataset to “test” the model in the training phase.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
